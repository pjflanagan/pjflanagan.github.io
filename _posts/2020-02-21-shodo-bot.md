---
layout: post
date: 2020-02-21
title: ShodoBot
description: Team Michelle calligraphy robot project with TOM
image: /assets/posts/2020/shodo-bot/shodo-bot.jpg
github: https://github.com/Team-Michelle-Calligraphy/calligraphy
website: https://tomglobal.org/project?id=5e3b942bd848736b09554581
---

A coworker asked me to help volunteer at a Hackathon with students at Columbia. The TOM program pairs engineers and individuals with special needs to help create tools to assist them. My team was paired with a woman named Michelle who likes to do calligraphy but has limited motor functions. She is very capable of controlling a computer using eye tracking software, so we devised a 3D-printer-style robot that can make brush strokes.

## The Build

My team members with robotics experience spearheaded the construction of the robot. The robot would angle, lift, and zig-zag the brush across the x-axis. To make vertical stroked, the robot would slide the paper itself up and down.

![Shodo Bot Overhead](/assets/posts/2020/shodo-bot/shodo-1-build-1.jpg)

![Shodo Bot Side Shot](/assets/posts/2020/shodo-bot/shodo-1-build-2.jpg)

## The UI

As a web developer, I was in charge of the UI. While I have plenty of experience making web apps and some Arduino projects under my belt, I have never paired the two. Making a web UI capable of controlling a robot was very exciting.

The first problem was figuring out how to interface the two. In order to do that, we had to find the open socket on the Arduino. 

![Shodo Bot UI Port Selection](/assets/posts/2020/shodo-bot/shodo-2-ui-1-port.png)

The interface featured a canvas that previewed the strokes, a series of moves that could be edited to make the stroke, and saved commands with known strokes and actions like dipping the brush in more ink. 

![Shodo Bot UI Movement](/assets/posts/2020/shodo-bot/shodo-2-ui-2-move.png)

...

![Shodo Bot UI Drawing](/assets/posts/2020/shodo-bot/shodo-2-ui-3-draw.png)

...

![Shodo Bot UI Final](/assets/posts/2020/shodo-bot/shodo-2-ui-final.png)

After a whole weekend at the Hackathon, I got the UI to a much more comprehensive place. We would save strokes as `.stroke` files. The UI displayed the angle of the brush, with a pressure indicator. The current and next position we're described on screen. And the buttons to move the brush could easily be pressed with eye-tracking software.


## The Final Project

![Shodo Bot Final Presentation](/assets/posts/2020/shodo-bot/shodo-3-final-presentation.jpg)

![Shodo Bot Final Kanji](/assets/posts/2020/shodo-bot/shodo-3-final-kanji.jpg)
